Processing aime: /root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet -> ./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet
Starting generation for aime at Sun Nov  2 23:59:10 CST 2025
2025-11-02 23:59:17,587	WARNING utils.py:460 -- Detecting docker specified CPUs. In previous versions of Ray, CPU detection in containers was incorrect. Please ensure that Ray has enough CPUs allocated. As a temporary workaround to revert to the prior behavior, set `RAY_USE_MULTIPROCESSING_CPU_COUNT=1` as an env var before starting Ray. Set the env var: `RAY_DISABLE_DOCKER_CPU_WARNING=1` to mute this warning.
2025-11-02 23:59:17,904	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(main_task pid=168871)[0m WARNING:2025-11-02 23:59:23,519:Waiting for register center actor P0zQ9X_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(main_task pid=168871)[0m {'actor': {'entropy_checkpointing': False,
[36m(main_task pid=168871)[0m            'entropy_from_logits_with_chunking': False,
[36m(main_task pid=168871)[0m            'fsdp_config': {'forward_prefetch': False, 'fsdp_size': -1},
[36m(main_task pid=168871)[0m            'strategy': 'fsdp',
[36m(main_task pid=168871)[0m            'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=168871)[0m  'data': {'batch_size': 16,
[36m(main_task pid=168871)[0m           'n_samples': 4,
[36m(main_task pid=168871)[0m           'output_path': './evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet',
[36m(main_task pid=168871)[0m           'path': '/root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet',
[36m(main_task pid=168871)[0m           'prompt_key': 'prompt'},
[36m(main_task pid=168871)[0m  'model': {'external_lib': None,
[36m(main_task pid=168871)[0m            'path': '/root/autodl-tmp/Qwen2.5-1.5B-Instruct',
[36m(main_task pid=168871)[0m            'trust_remote_code': True},
[36m(main_task pid=168871)[0m  'ray_init': {'num_cpus': None, 'timeline_json_file': None},
[36m(main_task pid=168871)[0m  'rollout': {'calculate_log_probs': False,
[36m(main_task pid=168871)[0m              'disable_log_stats': True,
[36m(main_task pid=168871)[0m              'do_sample': True,
[36m(main_task pid=168871)[0m              'dtype': 'bfloat16',
[36m(main_task pid=168871)[0m              'enable_chunked_prefill': True,
[36m(main_task pid=168871)[0m              'enforce_eager': True,
[36m(main_task pid=168871)[0m              'free_cache_engine': True,
[36m(main_task pid=168871)[0m              'gpu_memory_utilization': 0.9,
[36m(main_task pid=168871)[0m              'ignore_eos': False,
[36m(main_task pid=168871)[0m              'load_format': 'dummy_dtensor',
[36m(main_task pid=168871)[0m              'log_prob_micro_batch_size': None,
[36m(main_task pid=168871)[0m              'log_prob_micro_batch_size_per_gpu': 8,
[36m(main_task pid=168871)[0m              'max_model_len': None,
[36m(main_task pid=168871)[0m              'max_num_batched_tokens': 6144,
[36m(main_task pid=168871)[0m              'max_num_seqs': 1024,
[36m(main_task pid=168871)[0m              'mode': 'sync',
[36m(main_task pid=168871)[0m              'n': 1,
[36m(main_task pid=168871)[0m              'name': 'vllm',
[36m(main_task pid=168871)[0m              'prompt_length': 2048,
[36m(main_task pid=168871)[0m              'response_length': 4096,
[36m(main_task pid=168871)[0m              'temperature': 1.0,
[36m(main_task pid=168871)[0m              'tensor_model_parallel_size': 1,
[36m(main_task pid=168871)[0m              'top_k': 0,
[36m(main_task pid=168871)[0m              'top_p': 0.7},
[36m(main_task pid=168871)[0m  'trainer': {'device': 'cuda', 'n_gpus_per_node': 1, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=170176)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=1', 'data.path=/root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet', 'data.prompt_key=prompt', 'data.n_samples=4', 'data.batch_size=16', 'data.output_path=./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet', 'model.path=/root/autodl-tmp/Qwen2.5-1.5B-Instruct', '+model.trust_remote_code=True', 'rollout.temperature=1.0', 'rollout.top_k=0', 'rollout.top_p=0.7', 'rollout.prompt_length=2048', 'rollout.response_length=4096', 'rollout.max_num_batched_tokens=6144', 'rollout.tensor_model_parallel_size=1', 'rollout.gpu_memory_utilization=0.9']
Traceback (most recent call last):
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 104, in main
    run_generation(config)
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 115, in run_generation
    ray.get(main_task.remote(config))
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py", line 2961, in get
    values, debugger_breakpoint = worker.get_objects(
                                  ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py", line 1026, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ImportError): [36mray::main_task()[39m (pid=168871, ip=172.17.0.4)
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 185, in main_task
    wg.init_model()
  File "/root/autodl-tmp/Reasoning360/verl/single_controller/ray/base.py", line 50, in __call__
    output = ray.get(output)
             ^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^
                                  ^^^^^^^^^^^^^^^^^^^
ray.exceptions.RayTaskError(ImportError): [36mray::ActorRolloutRefWorker.init_model()[39m (pid=170176, ip=172.17.0.4, actor_id=2325a9857bc9222414a37e4101000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x7fd5f751b8c0>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/single_controller/base/decorator.py", line 689, in inner
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/workers/fsdp_workers.py", line 564, in init_model
    from verl.workers.actor import DataParallelPPOActor
  File "/root/autodl-tmp/Reasoning360/verl/workers/actor/__init__.py", line 16, in <module>
    from .dp_actor import DataParallelPPOActor
  File "/root/autodl-tmp/Reasoning360/verl/workers/actor/dp_actor.py", line 40, in <module>
    from flash_attn.bert_padding import index_first_axis, pad_input, rearrange, unpad_input
  File "/root/miniconda3/lib/python3.12/site-packages/flash_attn/__init__.py", line 3, in <module>
    from flash_attn.flash_attn_interface import (
  File "/root/miniconda3/lib/python3.12/site-packages/flash_attn/flash_attn_interface.py", line 15, in <module>
    import flash_attn_2_cuda as flash_attn_gpu
ImportError: /root/miniconda3/lib/python3.12/site-packages/flash_attn_2_cuda.cpython-312-x86_64-linux-gnu.so: undefined symbol: _ZN3c105ErrorC2ENS_14SourceLocationESs

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Processing aime: /root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet -> ./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet
Starting generation for aime at Mon Nov  3 00:05:14 CST 2025
2025-11-03 00:05:22,729	WARNING utils.py:460 -- Detecting docker specified CPUs. In previous versions of Ray, CPU detection in containers was incorrect. Please ensure that Ray has enough CPUs allocated. As a temporary workaround to revert to the prior behavior, set `RAY_USE_MULTIPROCESSING_CPU_COUNT=1` as an env var before starting Ray. Set the env var: `RAY_DISABLE_DOCKER_CPU_WARNING=1` to mute this warning.
2025-11-03 00:05:23,068	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(main_task pid=183048)[0m WARNING:2025-11-03 00:05:28,900:Waiting for register center actor 03O6dQ_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(ActorRolloutRefWorker pid=184593)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(main_task pid=183048)[0m {'actor': {'entropy_checkpointing': False,
[36m(main_task pid=183048)[0m            'entropy_from_logits_with_chunking': False,
[36m(main_task pid=183048)[0m            'fsdp_config': {'forward_prefetch': False, 'fsdp_size': -1},
[36m(main_task pid=183048)[0m            'strategy': 'fsdp',
[36m(main_task pid=183048)[0m            'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=183048)[0m  'data': {'batch_size': 16,
[36m(main_task pid=183048)[0m           'n_samples': 4,
[36m(main_task pid=183048)[0m           'output_path': './evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet',
[36m(main_task pid=183048)[0m           'path': '/root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet',
[36m(main_task pid=183048)[0m           'prompt_key': 'prompt'},
[36m(main_task pid=183048)[0m  'model': {'external_lib': None,
[36m(main_task pid=183048)[0m            'path': '/root/autodl-tmp/Qwen2.5-1.5B-Instruct',
[36m(main_task pid=183048)[0m            'trust_remote_code': True},
[36m(main_task pid=183048)[0m  'ray_init': {'num_cpus': None, 'timeline_json_file': None},
[36m(main_task pid=183048)[0m  'rollout': {'calculate_log_probs': False,
[36m(main_task pid=183048)[0m              'disable_log_stats': True,
[36m(main_task pid=183048)[0m              'do_sample': True,
[36m(main_task pid=183048)[0m              'dtype': 'bfloat16',
[36m(main_task pid=183048)[0m              'enable_chunked_prefill': True,
[36m(main_task pid=183048)[0m              'enforce_eager': True,
[36m(main_task pid=183048)[0m              'free_cache_engine': True,
[36m(main_task pid=183048)[0m              'gpu_memory_utilization': 0.9,
[36m(main_task pid=183048)[0m              'ignore_eos': False,
[36m(main_task pid=183048)[0m              'load_format': 'dummy_dtensor',
[36m(main_task pid=183048)[0m              'log_prob_micro_batch_size': None,
[36m(main_task pid=183048)[0m              'log_prob_micro_batch_size_per_gpu': 8,
[36m(main_task pid=183048)[0m              'max_model_len': None,
[36m(main_task pid=183048)[0m              'max_num_batched_tokens': 6144,
[36m(main_task pid=183048)[0m              'max_num_seqs': 1024,
[36m(main_task pid=183048)[0m              'mode': 'sync',
[36m(main_task pid=183048)[0m              'n': 1,
[36m(main_task pid=183048)[0m              'name': 'vllm',
[36m(main_task pid=183048)[0m              'prompt_length': 2048,
[36m(main_task pid=183048)[0m              'response_length': 4096,
[36m(main_task pid=183048)[0m              'temperature': 1.0,
[36m(main_task pid=183048)[0m              'tensor_model_parallel_size': 1,
[36m(main_task pid=183048)[0m              'top_k': 0,
[36m(main_task pid=183048)[0m              'top_p': 0.7},
[36m(main_task pid=183048)[0m  'trainer': {'device': 'cuda', 'n_gpus_per_node': 1, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=184593)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[36m(ActorRolloutRefWorker pid=184593)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=184593)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=184593)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=184593)[0m   ],
[36m(ActorRolloutRefWorker pid=184593)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=184593)[0m   "dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=184593)[0m   "eos_token_id": 151645,
[36m(ActorRolloutRefWorker pid=184593)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=184593)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=184593)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=184593)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=184593)[0m   "layer_types": [
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=184593)[0m     "full_attention"
[36m(ActorRolloutRefWorker pid=184593)[0m   ],
[36m(ActorRolloutRefWorker pid=184593)[0m   "max_position_embeddings": 32768,
[36m(ActorRolloutRefWorker pid=184593)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=184593)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=184593)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=184593)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=184593)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=184593)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=184593)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=184593)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=184593)[0m   "rope_theta": 1000000.0,
[36m(ActorRolloutRefWorker pid=184593)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=184593)[0m   "tie_word_embeddings": true,
[36m(ActorRolloutRefWorker pid=184593)[0m   "transformers_version": "4.57.1",
[36m(ActorRolloutRefWorker pid=184593)[0m   "use_cache": true,
[36m(ActorRolloutRefWorker pid=184593)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=184593)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=184593)[0m }
[36m(ActorRolloutRefWorker pid=184593)[0m 
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=1', 'data.path=/root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet', 'data.prompt_key=prompt', 'data.n_samples=4', 'data.batch_size=16', 'data.output_path=./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet', 'model.path=/root/autodl-tmp/Qwen2.5-1.5B-Instruct', '+model.trust_remote_code=True', 'rollout.temperature=1.0', 'rollout.top_k=0', 'rollout.top_p=0.7', 'rollout.prompt_length=2048', 'rollout.response_length=4096', 'rollout.max_num_batched_tokens=6144', 'rollout.tensor_model_parallel_size=1', 'rollout.gpu_memory_utilization=0.9']
Traceback (most recent call last):
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 104, in main
    run_generation(config)
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 115, in run_generation
    ray.get(main_task.remote(config))
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py", line 2961, in get
    values, debugger_breakpoint = worker.get_objects(
                                  ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py", line 1026, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(SafetensorError): [36mray::main_task()[39m (pid=183048, ip=172.17.0.4)
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 185, in main_task
    wg.init_model()
  File "/root/autodl-tmp/Reasoning360/verl/single_controller/ray/base.py", line 50, in __call__
    output = ray.get(output)
             ^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^
                                  ^^^^^^^^^^^^^^^^^^^
ray.exceptions.RayTaskError(SafetensorError): [36mray::ActorRolloutRefWorker.init_model()[39m (pid=184593, ip=172.17.0.4, actor_id=ab4eff6f8a53fa0b58d27d3801000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x7ef6eb3435f0>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/single_controller/base/decorator.py", line 689, in inner
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/workers/fsdp_workers.py", line 588, in init_model
    ) = self._build_model_optimizer(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/workers/fsdp_workers.py", line 285, in _build_model_optimizer
    actor_module = actor_module_class.from_pretrained(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_utils.py", line 4925, in from_pretrained
    with safe_open(checkpoint_files[0], framework="pt") as f:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
safetensors_rust.SafetensorError: Error while deserializing header: header too large

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Processing aime: /root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet -> ./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet
Starting generation for aime at Mon Nov  3 00:19:40 CST 2025
2025-11-03 00:19:48,258	WARNING utils.py:460 -- Detecting docker specified CPUs. In previous versions of Ray, CPU detection in containers was incorrect. Please ensure that Ray has enough CPUs allocated. As a temporary workaround to revert to the prior behavior, set `RAY_USE_MULTIPROCESSING_CPU_COUNT=1` as an env var before starting Ray. Set the env var: `RAY_DISABLE_DOCKER_CPU_WARNING=1` to mute this warning.
2025-11-03 00:19:48,581	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(main_task pid=206661)[0m WARNING:2025-11-03 00:19:54,170:Waiting for register center actor tzTKa9_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(ActorRolloutRefWorker pid=207927)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(main_task pid=206661)[0m {'actor': {'entropy_checkpointing': False,
[36m(main_task pid=206661)[0m            'entropy_from_logits_with_chunking': False,
[36m(main_task pid=206661)[0m            'fsdp_config': {'forward_prefetch': False, 'fsdp_size': -1},
[36m(main_task pid=206661)[0m            'strategy': 'fsdp',
[36m(main_task pid=206661)[0m            'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=206661)[0m  'data': {'batch_size': 16,
[36m(main_task pid=206661)[0m           'n_samples': 4,
[36m(main_task pid=206661)[0m           'output_path': './evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet',
[36m(main_task pid=206661)[0m           'path': '/root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet',
[36m(main_task pid=206661)[0m           'prompt_key': 'prompt'},
[36m(main_task pid=206661)[0m  'model': {'external_lib': None,
[36m(main_task pid=206661)[0m            'path': '/root/autodl-tmp/Qwen2.5-1.5B-Instruct',
[36m(main_task pid=206661)[0m            'trust_remote_code': True},
[36m(main_task pid=206661)[0m  'ray_init': {'num_cpus': None, 'timeline_json_file': None},
[36m(main_task pid=206661)[0m  'rollout': {'calculate_log_probs': False,
[36m(main_task pid=206661)[0m              'disable_log_stats': True,
[36m(main_task pid=206661)[0m              'do_sample': True,
[36m(main_task pid=206661)[0m              'dtype': 'bfloat16',
[36m(main_task pid=206661)[0m              'enable_chunked_prefill': True,
[36m(main_task pid=206661)[0m              'enforce_eager': True,
[36m(main_task pid=206661)[0m              'free_cache_engine': True,
[36m(main_task pid=206661)[0m              'gpu_memory_utilization': 0.9,
[36m(main_task pid=206661)[0m              'ignore_eos': False,
[36m(main_task pid=206661)[0m              'load_format': 'dummy_dtensor',
[36m(main_task pid=206661)[0m              'log_prob_micro_batch_size': None,
[36m(main_task pid=206661)[0m              'log_prob_micro_batch_size_per_gpu': 8,
[36m(main_task pid=206661)[0m              'max_model_len': None,
[36m(main_task pid=206661)[0m              'max_num_batched_tokens': 6144,
[36m(main_task pid=206661)[0m              'max_num_seqs': 1024,
[36m(main_task pid=206661)[0m              'mode': 'sync',
[36m(main_task pid=206661)[0m              'n': 1,
[36m(main_task pid=206661)[0m              'name': 'vllm',
[36m(main_task pid=206661)[0m              'prompt_length': 2048,
[36m(main_task pid=206661)[0m              'response_length': 4096,
[36m(main_task pid=206661)[0m              'temperature': 1.0,
[36m(main_task pid=206661)[0m              'tensor_model_parallel_size': 1,
[36m(main_task pid=206661)[0m              'top_k': 0,
[36m(main_task pid=206661)[0m              'top_p': 0.7},
[36m(main_task pid=206661)[0m  'trainer': {'device': 'cuda', 'n_gpus_per_node': 1, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=207927)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[36m(ActorRolloutRefWorker pid=207927)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=207927)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=207927)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=207927)[0m   ],
[36m(ActorRolloutRefWorker pid=207927)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=207927)[0m   "dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=207927)[0m   "eos_token_id": 151645,
[36m(ActorRolloutRefWorker pid=207927)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=207927)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=207927)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=207927)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=207927)[0m   "layer_types": [
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=207927)[0m     "full_attention"
[36m(ActorRolloutRefWorker pid=207927)[0m   ],
[36m(ActorRolloutRefWorker pid=207927)[0m   "max_position_embeddings": 32768,
[36m(ActorRolloutRefWorker pid=207927)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=207927)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=207927)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=207927)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=207927)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=207927)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=207927)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=207927)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=207927)[0m   "rope_theta": 1000000.0,
[36m(ActorRolloutRefWorker pid=207927)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=207927)[0m   "tie_word_embeddings": true,
[36m(ActorRolloutRefWorker pid=207927)[0m   "transformers_version": "4.57.1",
[36m(ActorRolloutRefWorker pid=207927)[0m   "use_cache": true,
[36m(ActorRolloutRefWorker pid=207927)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=207927)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=207927)[0m }
[36m(ActorRolloutRefWorker pid=207927)[0m 
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=1', 'data.path=/root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet', 'data.prompt_key=prompt', 'data.n_samples=4', 'data.batch_size=16', 'data.output_path=./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet', 'model.path=/root/autodl-tmp/Qwen2.5-1.5B-Instruct', '+model.trust_remote_code=True', 'rollout.temperature=1.0', 'rollout.top_k=0', 'rollout.top_p=0.7', 'rollout.prompt_length=2048', 'rollout.response_length=4096', 'rollout.max_num_batched_tokens=6144', 'rollout.tensor_model_parallel_size=1', 'rollout.gpu_memory_utilization=0.9']
Traceback (most recent call last):
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 104, in main
    run_generation(config)
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 115, in run_generation
    ray.get(main_task.remote(config))
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py", line 2961, in get
    values, debugger_breakpoint = worker.get_objects(
                                  ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py", line 1026, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ImportError): [36mray::main_task()[39m (pid=206661, ip=172.17.0.4)
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 185, in main_task
    wg.init_model()
  File "/root/autodl-tmp/Reasoning360/verl/single_controller/ray/base.py", line 50, in __call__
    output = ray.get(output)
             ^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^
                                  ^^^^^^^^^^^^^^^^^^^
ray.exceptions.RayTaskError(ImportError): [36mray::ActorRolloutRefWorker.init_model()[39m (pid=207927, ip=172.17.0.4, actor_id=c6b5aeb89341fe7a356bec7e01000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x7f151edf3770>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/single_controller/base/decorator.py", line 689, in inner
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/workers/fsdp_workers.py", line 588, in init_model
    ) = self._build_model_optimizer(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/workers/fsdp_workers.py", line 285, in _build_model_optimizer
    actor_module = actor_module_class.from_pretrained(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_utils.py", line 4971, in from_pretrained
    model = cls(config, *model_args, **model_kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 409, in __init__
    super().__init__(config)
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_utils.py", line 2076, in __init__
    self.config._attn_implementation_internal = self._check_and_adjust_attn_implementation(
                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_utils.py", line 2691, in _check_and_adjust_attn_implementation
    lazy_import_flash_attention(applicable_attn_implementation, force_import=True)
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py", line 136, in lazy_import_flash_attention
    _flash_fn, _flash_varlen_fn, _pad_fn, _unpad_fn = _lazy_imports(implementation)
                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py", line 83, in _lazy_imports
    from flash_attn import flash_attn_func, flash_attn_varlen_func
  File "/root/miniconda3/lib/python3.12/site-packages/flash_attn/__init__.py", line 3, in <module>
    from flash_attn.flash_attn_interface import (
  File "/root/miniconda3/lib/python3.12/site-packages/flash_attn/flash_attn_interface.py", line 15, in <module>
    import flash_attn_2_cuda as flash_attn_gpu
ImportError: /root/miniconda3/lib/python3.12/site-packages/flash_attn_2_cuda.cpython-312-x86_64-linux-gnu.so: undefined symbol: _ZN3c105ErrorC2ENS_14SourceLocationESs

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Processing aime: /root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet -> ./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet
Starting generation for aime at Mon Nov  3 00:23:40 CST 2025
2025-11-03 00:23:47,960	WARNING utils.py:460 -- Detecting docker specified CPUs. In previous versions of Ray, CPU detection in containers was incorrect. Please ensure that Ray has enough CPUs allocated. As a temporary workaround to revert to the prior behavior, set `RAY_USE_MULTIPROCESSING_CPU_COUNT=1` as an env var before starting Ray. Set the env var: `RAY_DISABLE_DOCKER_CPU_WARNING=1` to mute this warning.
2025-11-03 00:23:48,300	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(main_task pid=213230)[0m WARNING:2025-11-03 00:23:53,919:Waiting for register center actor Ahpyzc_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(ActorRolloutRefWorker pid=214619)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(main_task pid=213230)[0m {'actor': {'entropy_checkpointing': False,
[36m(main_task pid=213230)[0m            'entropy_from_logits_with_chunking': False,
[36m(main_task pid=213230)[0m            'fsdp_config': {'forward_prefetch': False, 'fsdp_size': -1},
[36m(main_task pid=213230)[0m            'strategy': 'fsdp',
[36m(main_task pid=213230)[0m            'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=213230)[0m  'data': {'batch_size': 16,
[36m(main_task pid=213230)[0m           'n_samples': 4,
[36m(main_task pid=213230)[0m           'output_path': './evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet',
[36m(main_task pid=213230)[0m           'path': '/root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet',
[36m(main_task pid=213230)[0m           'prompt_key': 'prompt'},
[36m(main_task pid=213230)[0m  'model': {'external_lib': None,
[36m(main_task pid=213230)[0m            'path': '/root/autodl-tmp/Qwen2.5-1.5B-Instruct',
[36m(main_task pid=213230)[0m            'trust_remote_code': True},
[36m(main_task pid=213230)[0m  'ray_init': {'num_cpus': None, 'timeline_json_file': None},
[36m(main_task pid=213230)[0m  'rollout': {'calculate_log_probs': False,
[36m(main_task pid=213230)[0m              'disable_log_stats': True,
[36m(main_task pid=213230)[0m              'do_sample': True,
[36m(main_task pid=213230)[0m              'dtype': 'bfloat16',
[36m(main_task pid=213230)[0m              'enable_chunked_prefill': True,
[36m(main_task pid=213230)[0m              'enforce_eager': True,
[36m(main_task pid=213230)[0m              'free_cache_engine': True,
[36m(main_task pid=213230)[0m              'gpu_memory_utilization': 0.9,
[36m(main_task pid=213230)[0m              'ignore_eos': False,
[36m(main_task pid=213230)[0m              'load_format': 'dummy_dtensor',
[36m(main_task pid=213230)[0m              'log_prob_micro_batch_size': None,
[36m(main_task pid=213230)[0m              'log_prob_micro_batch_size_per_gpu': 8,
[36m(main_task pid=213230)[0m              'max_model_len': None,
[36m(main_task pid=213230)[0m              'max_num_batched_tokens': 6144,
[36m(main_task pid=213230)[0m              'max_num_seqs': 1024,
[36m(main_task pid=213230)[0m              'mode': 'sync',
[36m(main_task pid=213230)[0m              'n': 1,
[36m(main_task pid=213230)[0m              'name': 'vllm',
[36m(main_task pid=213230)[0m              'prompt_length': 2048,
[36m(main_task pid=213230)[0m              'response_length': 4096,
[36m(main_task pid=213230)[0m              'temperature': 1.0,
[36m(main_task pid=213230)[0m              'tensor_model_parallel_size': 1,
[36m(main_task pid=213230)[0m              'top_k': 0,
[36m(main_task pid=213230)[0m              'top_p': 0.7},
[36m(main_task pid=213230)[0m  'trainer': {'device': 'cuda', 'n_gpus_per_node': 1, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=214619)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[36m(ActorRolloutRefWorker pid=214619)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=214619)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=214619)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=214619)[0m   ],
[36m(ActorRolloutRefWorker pid=214619)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=214619)[0m   "dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=214619)[0m   "eos_token_id": 151645,
[36m(ActorRolloutRefWorker pid=214619)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=214619)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=214619)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=214619)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=214619)[0m   "layer_types": [
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=214619)[0m     "full_attention"
[36m(ActorRolloutRefWorker pid=214619)[0m   ],
[36m(ActorRolloutRefWorker pid=214619)[0m   "max_position_embeddings": 32768,
[36m(ActorRolloutRefWorker pid=214619)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=214619)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=214619)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=214619)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=214619)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=214619)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=214619)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=214619)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=214619)[0m   "rope_theta": 1000000.0,
[36m(ActorRolloutRefWorker pid=214619)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=214619)[0m   "tie_word_embeddings": true,
[36m(ActorRolloutRefWorker pid=214619)[0m   "transformers_version": "4.57.1",
[36m(ActorRolloutRefWorker pid=214619)[0m   "use_cache": true,
[36m(ActorRolloutRefWorker pid=214619)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=214619)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=214619)[0m }
[36m(ActorRolloutRefWorker pid=214619)[0m 
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=1', 'data.path=/root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet', 'data.prompt_key=prompt', 'data.n_samples=4', 'data.batch_size=16', 'data.output_path=./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet', 'model.path=/root/autodl-tmp/Qwen2.5-1.5B-Instruct', '+model.trust_remote_code=True', 'rollout.temperature=1.0', 'rollout.top_k=0', 'rollout.top_p=0.7', 'rollout.prompt_length=2048', 'rollout.response_length=4096', 'rollout.max_num_batched_tokens=6144', 'rollout.tensor_model_parallel_size=1', 'rollout.gpu_memory_utilization=0.9']
Traceback (most recent call last):
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 104, in main
    run_generation(config)
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 115, in run_generation
    ray.get(main_task.remote(config))
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py", line 2961, in get
    values, debugger_breakpoint = worker.get_objects(
                                  ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py", line 1026, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ImportError): [36mray::main_task()[39m (pid=213230, ip=172.17.0.4)
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 185, in main_task
    wg.init_model()
  File "/root/autodl-tmp/Reasoning360/verl/single_controller/ray/base.py", line 50, in __call__
    output = ray.get(output)
             ^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^
                                  ^^^^^^^^^^^^^^^^^^^
ray.exceptions.RayTaskError(ImportError): [36mray::ActorRolloutRefWorker.init_model()[39m (pid=214619, ip=172.17.0.4, actor_id=161fcf5934371d039529802c01000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x7fd22d0f79e0>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/single_controller/base/decorator.py", line 689, in inner
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/workers/fsdp_workers.py", line 588, in init_model
    ) = self._build_model_optimizer(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/workers/fsdp_workers.py", line 285, in _build_model_optimizer
    actor_module = actor_module_class.from_pretrained(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_utils.py", line 4971, in from_pretrained
    model = cls(config, *model_args, **model_kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 409, in __init__
    super().__init__(config)
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_utils.py", line 2076, in __init__
    self.config._attn_implementation_internal = self._check_and_adjust_attn_implementation(
                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_utils.py", line 2691, in _check_and_adjust_attn_implementation
    lazy_import_flash_attention(applicable_attn_implementation, force_import=True)
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py", line 136, in lazy_import_flash_attention
    _flash_fn, _flash_varlen_fn, _pad_fn, _unpad_fn = _lazy_imports(implementation)
                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py", line 83, in _lazy_imports
    from flash_attn import flash_attn_func, flash_attn_varlen_func
  File "/root/miniconda3/lib/python3.12/site-packages/flash_attn/__init__.py", line 3, in <module>
    from flash_attn.flash_attn_interface import (
  File "/root/miniconda3/lib/python3.12/site-packages/flash_attn/flash_attn_interface.py", line 15, in <module>
    import flash_attn_2_cuda as flash_attn_gpu
ImportError: /root/miniconda3/lib/python3.12/site-packages/flash_attn_2_cuda.cpython-312-x86_64-linux-gnu.so: undefined symbol: _ZN3c105ErrorC2ENS_14SourceLocationESs

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Processing aime: /root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet -> ./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet
Starting generation for aime at Mon Nov  3 00:24:14 CST 2025
2025-11-03 00:24:22,295	WARNING utils.py:460 -- Detecting docker specified CPUs. In previous versions of Ray, CPU detection in containers was incorrect. Please ensure that Ray has enough CPUs allocated. As a temporary workaround to revert to the prior behavior, set `RAY_USE_MULTIPROCESSING_CPU_COUNT=1` as an env var before starting Ray. Set the env var: `RAY_DISABLE_DOCKER_CPU_WARNING=1` to mute this warning.
2025-11-03 00:24:22,604	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(main_task pid=218839)[0m WARNING:2025-11-03 00:24:28,262:Waiting for register center actor e6r1S2_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(main_task pid=218839)[0m {'actor': {'entropy_checkpointing': False,
[36m(main_task pid=218839)[0m            'entropy_from_logits_with_chunking': False,
[36m(main_task pid=218839)[0m            'fsdp_config': {'forward_prefetch': False, 'fsdp_size': -1},
[36m(main_task pid=218839)[0m            'strategy': 'fsdp',
[36m(main_task pid=218839)[0m            'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=218839)[0m  'data': {'batch_size': 16,
[36m(main_task pid=218839)[0m           'n_samples': 4,
[36m(main_task pid=218839)[0m           'output_path': './evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet',
[36m(main_task pid=218839)[0m           'path': '/root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet',
[36m(main_task pid=218839)[0m           'prompt_key': 'prompt'},
[36m(main_task pid=218839)[0m  'model': {'external_lib': None,
[36m(main_task pid=218839)[0m            'path': '/root/autodl-tmp/Qwen2.5-1.5B-Instruct',
[36m(main_task pid=218839)[0m            'trust_remote_code': True},
[36m(main_task pid=218839)[0m  'ray_init': {'num_cpus': None, 'timeline_json_file': None},
[36m(main_task pid=218839)[0m  'rollout': {'calculate_log_probs': False,
[36m(main_task pid=218839)[0m              'disable_log_stats': True,
[36m(main_task pid=218839)[0m              'do_sample': True,
[36m(main_task pid=218839)[0m              'dtype': 'bfloat16',
[36m(main_task pid=218839)[0m              'enable_chunked_prefill': True,
[36m(main_task pid=218839)[0m              'enforce_eager': True,
[36m(main_task pid=218839)[0m              'free_cache_engine': True,
[36m(main_task pid=218839)[0m              'gpu_memory_utilization': 0.9,
[36m(main_task pid=218839)[0m              'ignore_eos': False,
[36m(main_task pid=218839)[0m              'load_format': 'dummy_dtensor',
[36m(main_task pid=218839)[0m              'log_prob_micro_batch_size': None,
[36m(main_task pid=218839)[0m              'log_prob_micro_batch_size_per_gpu': 8,
[36m(main_task pid=218839)[0m              'max_model_len': None,
[36m(main_task pid=218839)[0m              'max_num_batched_tokens': 6144,
[36m(main_task pid=218839)[0m              'max_num_seqs': 1024,
[36m(main_task pid=218839)[0m              'mode': 'sync',
[36m(main_task pid=218839)[0m              'n': 1,
[36m(main_task pid=218839)[0m              'name': 'vllm',
[36m(main_task pid=218839)[0m              'prompt_length': 2048,
[36m(main_task pid=218839)[0m              'response_length': 4096,
[36m(main_task pid=218839)[0m              'temperature': 1.0,
[36m(main_task pid=218839)[0m              'tensor_model_parallel_size': 1,
[36m(main_task pid=218839)[0m              'top_k': 0,
[36m(main_task pid=218839)[0m              'top_p': 0.7},
[36m(main_task pid=218839)[0m  'trainer': {'device': 'cuda', 'n_gpus_per_node': 1, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=220361)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[36m(ActorRolloutRefWorker pid=220361)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[36m(ActorRolloutRefWorker pid=220361)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=1', 'data.path=/root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet', 'data.prompt_key=prompt', 'data.n_samples=4', 'data.batch_size=16', 'data.output_path=./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet', 'model.path=/root/autodl-tmp/Qwen2.5-1.5B-Instruct', '+model.trust_remote_code=True', 'rollout.temperature=1.0', 'rollout.top_k=0', 'rollout.top_p=0.7', 'rollout.prompt_length=2048', 'rollout.response_length=4096', 'rollout.max_num_batched_tokens=6144', 'rollout.tensor_model_parallel_size=1', 'rollout.gpu_memory_utilization=0.9']
Traceback (most recent call last):
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 104, in main
    run_generation(config)
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 115, in run_generation
    ray.get(main_task.remote(config))
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py", line 2961, in get
    values, debugger_breakpoint = worker.get_objects(
                                  ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py", line 1026, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ModuleNotFoundError): [36mray::main_task()[39m (pid=218839, ip=172.17.0.4)
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 185, in main_task
    wg.init_model()
  File "/root/autodl-tmp/Reasoning360/verl/single_controller/ray/base.py", line 50, in __call__
    output = ray.get(output)
             ^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^
                                  ^^^^^^^^^^^^^^^^^^^
ray.exceptions.RayTaskError(ModuleNotFoundError): [36mray::ActorRolloutRefWorker.init_model()[39m (pid=220361, ip=172.17.0.4, actor_id=4faf03ea1b6b23bed1a91cf501000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x7eff4060b920>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/single_controller/base/decorator.py", line 689, in inner
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/workers/fsdp_workers.py", line 569, in init_model
    self.rollout, self.rollout_sharding_manager = self._build_rollout(
                                                  ^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/workers/fsdp_workers.py", line 481, in _build_rollout
    from verl.workers.rollout.vllm_rollout import vLLMRollout
  File "/root/autodl-tmp/Reasoning360/verl/workers/rollout/vllm_rollout/__init__.py", line 17, in <module>
    from .vllm_rollout_spmd import vLLMAsyncRollout, vLLMRollout  # noqa: F401
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/workers/rollout/vllm_rollout/vllm_rollout_spmd.py", line 47, in <module>
    from vllm import LLM, SamplingParams
ModuleNotFoundError: No module named 'vllm'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Processing aime: /root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet -> ./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet
Starting generation for aime at Mon Nov  3 00:28:06 CST 2025
2025-11-03 00:28:14,305	WARNING utils.py:460 -- Detecting docker specified CPUs. In previous versions of Ray, CPU detection in containers was incorrect. Please ensure that Ray has enough CPUs allocated. As a temporary workaround to revert to the prior behavior, set `RAY_USE_MULTIPROCESSING_CPU_COUNT=1` as an env var before starting Ray. Set the env var: `RAY_DISABLE_DOCKER_CPU_WARNING=1` to mute this warning.
2025-11-03 00:28:14,624	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(main_task pid=228495)[0m WARNING:2025-11-03 00:28:20,206:Waiting for register center actor Hq4d8o_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(main_task pid=228495)[0m {'actor': {'entropy_checkpointing': False,
[36m(main_task pid=228495)[0m            'entropy_from_logits_with_chunking': False,
[36m(main_task pid=228495)[0m            'fsdp_config': {'forward_prefetch': False, 'fsdp_size': -1},
[36m(main_task pid=228495)[0m            'strategy': 'fsdp',
[36m(main_task pid=228495)[0m            'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=228495)[0m  'data': {'batch_size': 16,
[36m(main_task pid=228495)[0m           'n_samples': 4,
[36m(main_task pid=228495)[0m           'output_path': './evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet',
[36m(main_task pid=228495)[0m           'path': '/root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet',
[36m(main_task pid=228495)[0m           'prompt_key': 'prompt'},
[36m(main_task pid=228495)[0m  'model': {'external_lib': None,
[36m(main_task pid=228495)[0m            'path': '/root/autodl-tmp/Qwen2.5-1.5B-Instruct',
[36m(main_task pid=228495)[0m            'trust_remote_code': True},
[36m(main_task pid=228495)[0m  'ray_init': {'num_cpus': None, 'timeline_json_file': None},
[36m(main_task pid=228495)[0m  'rollout': {'calculate_log_probs': False,
[36m(main_task pid=228495)[0m              'disable_log_stats': True,
[36m(main_task pid=228495)[0m              'do_sample': True,
[36m(main_task pid=228495)[0m              'dtype': 'bfloat16',
[36m(main_task pid=228495)[0m              'enable_chunked_prefill': True,
[36m(main_task pid=228495)[0m              'enforce_eager': True,
[36m(main_task pid=228495)[0m              'free_cache_engine': True,
[36m(main_task pid=228495)[0m              'gpu_memory_utilization': 0.9,
[36m(main_task pid=228495)[0m              'ignore_eos': False,
[36m(main_task pid=228495)[0m              'load_format': 'dummy_dtensor',
[36m(main_task pid=228495)[0m              'log_prob_micro_batch_size': None,
[36m(main_task pid=228495)[0m              'log_prob_micro_batch_size_per_gpu': 8,
[36m(main_task pid=228495)[0m              'max_model_len': None,
[36m(main_task pid=228495)[0m              'max_num_batched_tokens': 6144,
[36m(main_task pid=228495)[0m              'max_num_seqs': 1024,
[36m(main_task pid=228495)[0m              'mode': 'sync',
[36m(main_task pid=228495)[0m              'n': 1,
[36m(main_task pid=228495)[0m              'name': 'vllm',
[36m(main_task pid=228495)[0m              'prompt_length': 2048,
[36m(main_task pid=228495)[0m              'response_length': 4096,
[36m(main_task pid=228495)[0m              'temperature': 1.0,
[36m(main_task pid=228495)[0m              'tensor_model_parallel_size': 1,
[36m(main_task pid=228495)[0m              'top_k': 0,
[36m(main_task pid=228495)[0m              'top_p': 0.7},
[36m(main_task pid=228495)[0m  'trainer': {'device': 'cuda', 'n_gpus_per_node': 1, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=229885)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
Error executing job with overrides: ['trainer.nnodes=1', 'trainer.n_gpus_per_node=1', 'data.path=/root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet', 'data.prompt_key=prompt', 'data.n_samples=4', 'data.batch_size=16', 'data.output_path=./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet', 'model.path=/root/autodl-tmp/Qwen2.5-1.5B-Instruct', '+model.trust_remote_code=True', 'rollout.temperature=1.0', 'rollout.top_k=0', 'rollout.top_p=0.7', 'rollout.prompt_length=2048', 'rollout.response_length=4096', 'rollout.max_num_batched_tokens=6144', 'rollout.tensor_model_parallel_size=1', 'rollout.gpu_memory_utilization=0.9']
Traceback (most recent call last):
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 104, in main
    run_generation(config)
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 115, in run_generation
    ray.get(main_task.remote(config))
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py", line 2961, in get
    values, debugger_breakpoint = worker.get_objects(
                                  ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py", line 1026, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ModuleNotFoundError): [36mray::main_task()[39m (pid=228495, ip=172.17.0.4)
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 185, in main_task
    wg.init_model()
  File "/root/autodl-tmp/Reasoning360/verl/single_controller/ray/base.py", line 50, in __call__
    output = ray.get(output)
             ^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^
                                  ^^^^^^^^^^^^^^^^^^^
ray.exceptions.RayTaskError(ModuleNotFoundError): [36mray::ActorRolloutRefWorker.init_model()[39m (pid=229885, ip=172.17.0.4, actor_id=b5ba12ee864c575ea9ad1a3801000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x7f63d7b27890>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/single_controller/base/decorator.py", line 689, in inner
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/workers/fsdp_workers.py", line 569, in init_model
    self.rollout, self.rollout_sharding_manager = self._build_rollout(
                                                  ^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/workers/fsdp_workers.py", line 481, in _build_rollout
    from verl.workers.rollout.vllm_rollout import vLLMRollout
  File "/root/autodl-tmp/Reasoning360/verl/workers/rollout/vllm_rollout/__init__.py", line 17, in <module>
    from .vllm_rollout_spmd import vLLMAsyncRollout, vLLMRollout  # noqa: F401
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/workers/rollout/vllm_rollout/vllm_rollout_spmd.py", line 47, in <module>
    from vllm import LLM, SamplingParams
ModuleNotFoundError: No module named 'vllm'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[36m(ActorRolloutRefWorker pid=229885)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[36m(ActorRolloutRefWorker pid=229885)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
Processing aime: /root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet -> ./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet
Starting generation for aime at Mon Nov  3 00:35:05 CST 2025
scripts/offline_eval/test.sh: line 135: output_path: unbound variable
Processing aime: /root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet -> ./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet
Starting generation for aime at Mon Nov  3 00:36:25 CST 2025
scripts/offline_eval/test.sh: line 136: output_path: unbound variable
Processing aime: /root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet -> ./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet
Starting generation for aime at Mon Nov  3 00:37:18 CST 2025
2025-11-03 00:37:25,757	WARNING utils.py:460 -- Detecting docker specified CPUs. In previous versions of Ray, CPU detection in containers was incorrect. Please ensure that Ray has enough CPUs allocated. As a temporary workaround to revert to the prior behavior, set `RAY_USE_MULTIPROCESSING_CPU_COUNT=1` as an env var before starting Ray. Set the env var: `RAY_DISABLE_DOCKER_CPU_WARNING=1` to mute this warning.
2025-11-03 00:37:26,128	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
Processing aime: /root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet -> ./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet
Starting generation for aime at Mon Nov  3 00:49:24 CST 2025
2025-11-03 00:49:32,614	WARNING utils.py:460 -- Detecting docker specified CPUs. In previous versions of Ray, CPU detection in containers was incorrect. Please ensure that Ray has enough CPUs allocated. As a temporary workaround to revert to the prior behavior, set `RAY_USE_MULTIPROCESSING_CPU_COUNT=1` as an env var before starting Ray. Set the env var: `RAY_DISABLE_DOCKER_CPU_WARNING=1` to mute this warning.
2025-11-03 00:49:32,940	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
Processing aime: /root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet -> ./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet
Starting generation for aime at Mon Nov  3 00:50:09 CST 2025
2025-11-03 00:50:19,100	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
Processing aime: /root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet -> ./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet
Starting generation for aime at Mon Nov  3 00:56:03 CST 2025
2025-11-03 00:56:12,716	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
Processing aime: /root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet -> ./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet
Starting generation for aime at Mon Nov  3 10:15:39 CST 2025
2025-11-03 10:15:48,788	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
Processing aime: /root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet -> ./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet
Starting generation for aime at Mon Nov  3 10:21:33 CST 2025
2025-11-03 10:21:42,612	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(main_task pid=21769)[0m WARNING:2025-11-03 10:21:47,881:Waiting for register center actor ckO6ee_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(main_task pid=21769)[0m {'actor': {'entropy_checkpointing': False,
[36m(main_task pid=21769)[0m            'entropy_from_logits_with_chunking': False,
[36m(main_task pid=21769)[0m            'fsdp_config': {'forward_prefetch': False, 'fsdp_size': -1},
[36m(main_task pid=21769)[0m            'strategy': 'fsdp',
[36m(main_task pid=21769)[0m            'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=21769)[0m  'data': {'batch_size': 16,
[36m(main_task pid=21769)[0m           'n_samples': 4,
[36m(main_task pid=21769)[0m           'output_path': './evaluation_results/test_offline_leaderboard_output/Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet',
[36m(main_task pid=21769)[0m           'path': '/root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet',
[36m(main_task pid=21769)[0m           'prompt_key': 'prompt'},
[36m(main_task pid=21769)[0m  'model': {'external_lib': None,
[36m(main_task pid=21769)[0m            'path': '/root/autodl-tmp/Qwen2.5-1.5B-Instruct',
[36m(main_task pid=21769)[0m            'trust_remote_code': True},
[36m(main_task pid=21769)[0m  'ray_init': {'num_cpus': 8, 'timeline_json_file': None},
[36m(main_task pid=21769)[0m  'rollout': {'calculate_log_probs': False,
[36m(main_task pid=21769)[0m              'disable_log_stats': True,
[36m(main_task pid=21769)[0m              'do_sample': True,
[36m(main_task pid=21769)[0m              'dtype': 'bfloat16',
[36m(main_task pid=21769)[0m              'enable_chunked_prefill': True,
[36m(main_task pid=21769)[0m              'enforce_eager': True,
[36m(main_task pid=21769)[0m              'free_cache_engine': True,
[36m(main_task pid=21769)[0m              'gpu_memory_utilization': 0.5,
[36m(main_task pid=21769)[0m              'ignore_eos': False,
[36m(main_task pid=21769)[0m              'load_format': 'dummy_dtensor',
[36m(main_task pid=21769)[0m              'log_prob_micro_batch_size': None,
[36m(main_task pid=21769)[0m              'log_prob_micro_batch_size_per_gpu': 8,
[36m(main_task pid=21769)[0m              'max_model_len': None,
[36m(main_task pid=21769)[0m              'max_num_batched_tokens': 8192,
[36m(main_task pid=21769)[0m              'max_num_seqs': 1024,
[36m(main_task pid=21769)[0m              'mode': 'sync',
[36m(main_task pid=21769)[0m              'n': 1,
[36m(main_task pid=21769)[0m              'name': 'hf',
[36m(main_task pid=21769)[0m              'prompt_length': 2048,
[36m(main_task pid=21769)[0m              'response_length': 4096,
[36m(main_task pid=21769)[0m              'temperature': 1.0,
[36m(main_task pid=21769)[0m              'tensor_model_parallel_size': 1,
[36m(main_task pid=21769)[0m              'top_k': 0,
[36m(main_task pid=21769)[0m              'top_p': 0.7},
[36m(main_task pid=21769)[0m  'trainer': {'device': 'cuda', 'n_gpus_per_node': 1, 'nnodes': 1}}
Error executing job with overrides: ['rollout.name=hf', 'trainer.nnodes=1', 'trainer.n_gpus_per_node=1', 'ray_init.num_cpus=8', 'model.path=/root/autodl-tmp/Qwen2.5-1.5B-Instruct', '+model.trust_remote_code=True', 'data.path=/root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet', 'data.prompt_key=prompt', 'data.n_samples=4', 'data.batch_size=16', 'data.output_path=./evaluation_results/test_offline_leaderboard_output/Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet', 'rollout.do_sample=True', 'rollout.temperature=1.0', 'rollout.top_k=0', 'rollout.top_p=0.7', 'rollout.prompt_length=2048', 'rollout.response_length=4096']
Traceback (most recent call last):
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 104, in main
    run_generation(config)
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 114, in run_generation
    ray.get(main_task.remote(config))
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py", line 2961, in get
    values, debugger_breakpoint = worker.get_objects(
                                  ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py", line 1026, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(AttributeError): [36mray::main_task()[39m (pid=21769, ip=172.17.0.11)
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 188, in main_task
    wg.init_model()
  File "/root/autodl-tmp/Reasoning360/verl/single_controller/ray/base.py", line 50, in __call__
    output = ray.get(output)
             ^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^
                                  ^^^^^^^^^^^^^^^^^^^
ray.exceptions.RayTaskError(AttributeError): [36mray::ActorRolloutRefWorker.init_model()[39m (pid=22484, ip=172.17.0.11, actor_id=ecf15e384af67912baf0e24901000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x7f7b0fd2b710>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/single_controller/base/decorator.py", line 689, in inner
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/workers/fsdp_workers.py", line 569, in init_model
    self.rollout, self.rollout_sharding_manager = self._build_rollout(
                                                  ^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/workers/fsdp_workers.py", line 476, in _build_rollout
    rollout = HFRollout(module=self.actor_module_fsdp, config=self.config.rollout)
                               ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ActorRolloutRefWorker' object has no attribute 'actor_module_fsdp'. Did you mean: '_return_value'?

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[36m(ActorRolloutRefWorker pid=22484)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[36m(ActorRolloutRefWorker pid=22484)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[36m(ActorRolloutRefWorker pid=22484)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
Processing aime: /root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet -> ./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet
Starting generation for aime at Mon Nov  3 10:24:52 CST 2025
2025-11-03 10:25:01,184	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(main_task pid=27851)[0m WARNING:2025-11-03 10:25:06,531:Waiting for register center actor gP8Jr0_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(ActorRolloutRefWorker pid=28638)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(main_task pid=27851)[0m {'actor': {'entropy_checkpointing': False,
[36m(main_task pid=27851)[0m            'entropy_from_logits_with_chunking': False,
[36m(main_task pid=27851)[0m            'fsdp_config': {'forward_prefetch': False, 'fsdp_size': -1},
[36m(main_task pid=27851)[0m            'strategy': 'fsdp',
[36m(main_task pid=27851)[0m            'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=27851)[0m  'data': {'batch_size': 16,
[36m(main_task pid=27851)[0m           'n_samples': 4,
[36m(main_task pid=27851)[0m           'output_path': './evaluation_results/test_offline_leaderboard_output/Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet',
[36m(main_task pid=27851)[0m           'path': '/root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet',
[36m(main_task pid=27851)[0m           'prompt_key': 'prompt'},
[36m(main_task pid=27851)[0m  'model': {'external_lib': None,
[36m(main_task pid=27851)[0m            'path': '/root/autodl-tmp/Qwen2.5-1.5B-Instruct',
[36m(main_task pid=27851)[0m            'trust_remote_code': True},
[36m(main_task pid=27851)[0m  'ray_init': {'num_cpus': 8, 'timeline_json_file': None},
[36m(main_task pid=27851)[0m  'rollout': {'calculate_log_probs': False,
[36m(main_task pid=27851)[0m              'disable_log_stats': True,
[36m(main_task pid=27851)[0m              'do_sample': True,
[36m(main_task pid=27851)[0m              'dtype': 'bfloat16',
[36m(main_task pid=27851)[0m              'enable_chunked_prefill': True,
[36m(main_task pid=27851)[0m              'enforce_eager': True,
[36m(main_task pid=27851)[0m              'free_cache_engine': True,
[36m(main_task pid=27851)[0m              'gpu_memory_utilization': 0.5,
[36m(main_task pid=27851)[0m              'ignore_eos': False,
[36m(main_task pid=27851)[0m              'load_format': 'dummy_dtensor',
[36m(main_task pid=27851)[0m              'log_prob_micro_batch_size': None,
[36m(main_task pid=27851)[0m              'log_prob_micro_batch_size_per_gpu': 8,
[36m(main_task pid=27851)[0m              'max_model_len': None,
[36m(main_task pid=27851)[0m              'max_num_batched_tokens': 8192,
[36m(main_task pid=27851)[0m              'max_num_seqs': 1024,
[36m(main_task pid=27851)[0m              'mode': 'sync',
[36m(main_task pid=27851)[0m              'n': 1,
[36m(main_task pid=27851)[0m              'name': 'hf',
[36m(main_task pid=27851)[0m              'prompt_length': 2048,
[36m(main_task pid=27851)[0m              'response_length': 4096,
[36m(main_task pid=27851)[0m              'temperature': 1.0,
[36m(main_task pid=27851)[0m              'tensor_model_parallel_size': 1,
[36m(main_task pid=27851)[0m              'top_k': 0,
[36m(main_task pid=27851)[0m              'top_p': 0.7},
[36m(main_task pid=27851)[0m  'trainer': {'device': 'cuda', 'n_gpus_per_node': 1, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=28638)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[36m(ActorRolloutRefWorker pid=28638)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=28638)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=28638)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=28638)[0m   ],
[36m(ActorRolloutRefWorker pid=28638)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=28638)[0m   "dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=28638)[0m   "eos_token_id": 151645,
[36m(ActorRolloutRefWorker pid=28638)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=28638)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=28638)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=28638)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=28638)[0m   "layer_types": [
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=28638)[0m     "full_attention"
[36m(ActorRolloutRefWorker pid=28638)[0m   ],
[36m(ActorRolloutRefWorker pid=28638)[0m   "max_position_embeddings": 32768,
[36m(ActorRolloutRefWorker pid=28638)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=28638)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=28638)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=28638)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=28638)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=28638)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=28638)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=28638)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=28638)[0m   "rope_theta": 1000000.0,
[36m(ActorRolloutRefWorker pid=28638)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=28638)[0m   "tie_word_embeddings": true,
[36m(ActorRolloutRefWorker pid=28638)[0m   "transformers_version": "4.57.1",
[36m(ActorRolloutRefWorker pid=28638)[0m   "use_cache": true,
[36m(ActorRolloutRefWorker pid=28638)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=28638)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=28638)[0m }
[36m(ActorRolloutRefWorker pid=28638)[0m 
Error executing job with overrides: ['rollout.name=hf', 'trainer.nnodes=1', 'trainer.n_gpus_per_node=1', 'ray_init.num_cpus=8', 'model.path=/root/autodl-tmp/Qwen2.5-1.5B-Instruct', '+model.trust_remote_code=True', 'data.path=/root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet', 'data.prompt_key=prompt', 'data.n_samples=4', 'data.batch_size=16', 'data.output_path=./evaluation_results/test_offline_leaderboard_output/Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet', 'rollout.do_sample=True', 'rollout.temperature=1.0', 'rollout.top_k=0', 'rollout.top_p=0.7', 'rollout.prompt_length=2048', 'rollout.response_length=4096']
Traceback (most recent call last):
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 104, in main
    run_generation(config)
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 114, in run_generation
    ray.get(main_task.remote(config))
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py", line 2961, in get
    values, debugger_breakpoint = worker.get_objects(
                                  ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py", line 1026, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ImportError): [36mray::main_task()[39m (pid=27851, ip=172.17.0.11)
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 188, in main_task
    wg.init_model()
  File "/root/autodl-tmp/Reasoning360/verl/single_controller/ray/base.py", line 50, in __call__
    output = ray.get(output)
             ^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^
                                  ^^^^^^^^^^^^^^^^^^^
ray.exceptions.RayTaskError(ImportError): [36mray::ActorRolloutRefWorker.init_model()[39m (pid=28638, ip=172.17.0.11, actor_id=e1a1fe4228adf826e1600fe001000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x7f9570bfb7a0>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/single_controller/base/decorator.py", line 689, in inner
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/workers/fsdp_workers.py", line 597, in init_model
    ) = self._build_model_optimizer(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/workers/fsdp_workers.py", line 285, in _build_model_optimizer
    actor_module = actor_module_class.from_pretrained(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_utils.py", line 4971, in from_pretrained
    model = cls(config, *model_args, **model_kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 409, in __init__
    super().__init__(config)
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_utils.py", line 2076, in __init__
    self.config._attn_implementation_internal = self._check_and_adjust_attn_implementation(
                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_utils.py", line 2691, in _check_and_adjust_attn_implementation
    lazy_import_flash_attention(applicable_attn_implementation, force_import=True)
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py", line 136, in lazy_import_flash_attention
    _flash_fn, _flash_varlen_fn, _pad_fn, _unpad_fn = _lazy_imports(implementation)
                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py", line 83, in _lazy_imports
    from flash_attn import flash_attn_func, flash_attn_varlen_func
  File "/root/miniconda3/lib/python3.12/site-packages/flash_attn/__init__.py", line 3, in <module>
    from flash_attn.flash_attn_interface import (
  File "/root/miniconda3/lib/python3.12/site-packages/flash_attn/flash_attn_interface.py", line 15, in <module>
    import flash_attn_2_cuda as flash_attn_gpu
ImportError: /root/miniconda3/lib/python3.12/site-packages/flash_attn_2_cuda.cpython-312-x86_64-linux-gnu.so: undefined symbol: _ZN3c105ErrorC2ENS_14SourceLocationESs

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Processing aime: /root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet -> ./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet
Starting generation for aime at Mon Nov  3 10:29:10 CST 2025
DISABLE_RAY=1 detected; using local HF generation on single GPU.
Error executing job with overrides: ['rollout.name=hf', 'trainer.nnodes=1', 'trainer.n_gpus_per_node=1', 'ray_init.num_cpus=8', 'model.path=/root/autodl-tmp/Qwen2.5-1.5B-Instruct', '+model.trust_remote_code=True', 'data.path=/root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet', 'data.prompt_key=prompt', 'data.n_samples=4', 'data.batch_size=16', 'data.output_path=./evaluation_results/test_offline_leaderboard_output/Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet', 'rollout.do_sample=True', 'rollout.temperature=1.0', 'rollout.top_k=0', 'rollout.top_p=0.7', 'rollout.prompt_length=2048', 'rollout.response_length=4096']
Traceback (most recent call last):
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 104, in main
    run_generation(config)
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 110, in run_generation
    run_generation_local(config)
  File "/root/miniconda3/lib/python3.12/site-packages/ray/remote_function.py", line 173, in __call__
    raise TypeError(
TypeError: Remote functions cannot be called directly. Instead of running '__main__.run_generation_local()', try '__main__.run_generation_local.remote()'.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Processing aime: /root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet -> ./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet
Starting generation for aime at Mon Nov  3 10:31:49 CST 2025
`torch_dtype` is deprecated! Use `dtype` instead!
Processing aime: /root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet -> ./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet
Starting generation for aime at Mon Nov  3 12:48:54 CST 2025
2025-11-03 12:49:02,812	INFO worker.py:2003 -- Started a local Ray instance. View the dashboard at [1m[32mhttp://127.0.0.1:8265 [39m[22m
/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py:2051: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[36m(main_task pid=228111)[0m WARNING:2025-11-03 12:49:08,783:Waiting for register center actor 2OZrFW_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(ActorRolloutRefWorker pid=229126)[0m `torch_dtype` is deprecated! Use `dtype` instead!
[36m(main_task pid=228111)[0m {'actor': {'entropy_checkpointing': False,
[36m(main_task pid=228111)[0m            'entropy_from_logits_with_chunking': False,
[36m(main_task pid=228111)[0m            'fsdp_config': {'forward_prefetch': False, 'fsdp_size': -1},
[36m(main_task pid=228111)[0m            'strategy': 'fsdp',
[36m(main_task pid=228111)[0m            'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=228111)[0m  'data': {'batch_size': 16,
[36m(main_task pid=228111)[0m           'n_samples': 4,
[36m(main_task pid=228111)[0m           'output_path': './evaluation_results/test_offline_leaderboard_output/Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet',
[36m(main_task pid=228111)[0m           'path': '/root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet',
[36m(main_task pid=228111)[0m           'prompt_key': 'prompt'},
[36m(main_task pid=228111)[0m  'model': {'external_lib': None,
[36m(main_task pid=228111)[0m            'path': '/root/autodl-tmp/Qwen2.5-1.5B-Instruct',
[36m(main_task pid=228111)[0m            'trust_remote_code': True},
[36m(main_task pid=228111)[0m  'ray_init': {'num_cpus': 25, 'timeline_json_file': None},
[36m(main_task pid=228111)[0m  'rollout': {'calculate_log_probs': False,
[36m(main_task pid=228111)[0m              'disable_log_stats': True,
[36m(main_task pid=228111)[0m              'do_sample': True,
[36m(main_task pid=228111)[0m              'dtype': 'bfloat16',
[36m(main_task pid=228111)[0m              'enable_chunked_prefill': True,
[36m(main_task pid=228111)[0m              'enforce_eager': True,
[36m(main_task pid=228111)[0m              'free_cache_engine': True,
[36m(main_task pid=228111)[0m              'gpu_memory_utilization': 0.5,
[36m(main_task pid=228111)[0m              'ignore_eos': False,
[36m(main_task pid=228111)[0m              'load_format': 'dummy_dtensor',
[36m(main_task pid=228111)[0m              'log_prob_micro_batch_size': None,
[36m(main_task pid=228111)[0m              'log_prob_micro_batch_size_per_gpu': 8,
[36m(main_task pid=228111)[0m              'max_model_len': None,
[36m(main_task pid=228111)[0m              'max_num_batched_tokens': 8192,
[36m(main_task pid=228111)[0m              'max_num_seqs': 1024,
[36m(main_task pid=228111)[0m              'mode': 'sync',
[36m(main_task pid=228111)[0m              'n': 1,
[36m(main_task pid=228111)[0m              'name': 'hf',
[36m(main_task pid=228111)[0m              'prompt_length': 2048,
[36m(main_task pid=228111)[0m              'response_length': 4096,
[36m(main_task pid=228111)[0m              'temperature': 1.0,
[36m(main_task pid=228111)[0m              'tensor_model_parallel_size': 1,
[36m(main_task pid=228111)[0m              'top_k': 0,
[36m(main_task pid=228111)[0m              'top_p': 0.7},
[36m(main_task pid=228111)[0m  'trainer': {'device': 'cuda', 'n_gpus_per_node': 1, 'nnodes': 1}}
[36m(ActorRolloutRefWorker pid=229126)[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[36m(ActorRolloutRefWorker pid=229126)[0m Model config after override: Qwen2Config {
[36m(ActorRolloutRefWorker pid=229126)[0m   "architectures": [
[36m(ActorRolloutRefWorker pid=229126)[0m     "Qwen2ForCausalLM"
[36m(ActorRolloutRefWorker pid=229126)[0m   ],
[36m(ActorRolloutRefWorker pid=229126)[0m   "attention_dropout": 0.0,
[36m(ActorRolloutRefWorker pid=229126)[0m   "dtype": "bfloat16",
[36m(ActorRolloutRefWorker pid=229126)[0m   "eos_token_id": 151645,
[36m(ActorRolloutRefWorker pid=229126)[0m   "hidden_act": "silu",
[36m(ActorRolloutRefWorker pid=229126)[0m   "hidden_size": 1536,
[36m(ActorRolloutRefWorker pid=229126)[0m   "initializer_range": 0.02,
[36m(ActorRolloutRefWorker pid=229126)[0m   "intermediate_size": 8960,
[36m(ActorRolloutRefWorker pid=229126)[0m   "layer_types": [
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention",
[36m(ActorRolloutRefWorker pid=229126)[0m     "full_attention"
[36m(ActorRolloutRefWorker pid=229126)[0m   ],
[36m(ActorRolloutRefWorker pid=229126)[0m   "max_position_embeddings": 32768,
[36m(ActorRolloutRefWorker pid=229126)[0m   "max_window_layers": 21,
[36m(ActorRolloutRefWorker pid=229126)[0m   "model_type": "qwen2",
[36m(ActorRolloutRefWorker pid=229126)[0m   "num_attention_heads": 12,
[36m(ActorRolloutRefWorker pid=229126)[0m   "num_hidden_layers": 28,
[36m(ActorRolloutRefWorker pid=229126)[0m   "num_key_value_heads": 2,
[36m(ActorRolloutRefWorker pid=229126)[0m   "pad_token_id": 151643,
[36m(ActorRolloutRefWorker pid=229126)[0m   "rms_norm_eps": 1e-06,
[36m(ActorRolloutRefWorker pid=229126)[0m   "rope_scaling": null,
[36m(ActorRolloutRefWorker pid=229126)[0m   "rope_theta": 1000000.0,
[36m(ActorRolloutRefWorker pid=229126)[0m   "sliding_window": null,
[36m(ActorRolloutRefWorker pid=229126)[0m   "tie_word_embeddings": true,
[36m(ActorRolloutRefWorker pid=229126)[0m   "transformers_version": "4.57.1",
[36m(ActorRolloutRefWorker pid=229126)[0m   "use_cache": true,
[36m(ActorRolloutRefWorker pid=229126)[0m   "use_sliding_window": false,
[36m(ActorRolloutRefWorker pid=229126)[0m   "vocab_size": 151936
[36m(ActorRolloutRefWorker pid=229126)[0m }
[36m(ActorRolloutRefWorker pid=229126)[0m 
Error executing job with overrides: ['rollout.name=hf', 'trainer.nnodes=1', 'trainer.n_gpus_per_node=1', 'ray_init.num_cpus=25', 'model.path=/root/autodl-tmp/Qwen2.5-1.5B-Instruct', '+model.trust_remote_code=True', 'data.path=/root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet', 'data.prompt_key=prompt', 'data.n_samples=4', 'data.batch_size=16', 'data.output_path=./evaluation_results/test_offline_leaderboard_output/Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet', 'rollout.do_sample=True', 'rollout.temperature=1.0', 'rollout.top_k=0', 'rollout.top_p=0.7', 'rollout.prompt_length=2048', 'rollout.response_length=4096']
Traceback (most recent call last):
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 104, in main
    run_generation(config)
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 117, in run_generation
    ray.get(main_task.remote(config))
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py", line 2961, in get
    values, debugger_breakpoint = worker.get_objects(
                                  ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/ray/_private/worker.py", line 1026, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ImportError): [36mray::main_task()[39m (pid=228111, ip=172.17.0.11)
  File "/root/autodl-tmp/Reasoning360/verl/trainer/main_generation.py", line 191, in main_task
    wg.init_model()
  File "/root/autodl-tmp/Reasoning360/verl/single_controller/ray/base.py", line 50, in __call__
    output = ray.get(output)
             ^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^
                                  ^^^^^^^^^^^^^^^^^^^
ray.exceptions.RayTaskError(ImportError): [36mray::ActorRolloutRefWorker.init_model()[39m (pid=229126, ip=172.17.0.11, actor_id=816b1804876af8f1db0ab13b01000000, repr=<verl.workers.fsdp_workers.ActorRolloutRefWorker object at 0x7f8980febcb0>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/single_controller/base/decorator.py", line 689, in inner
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/workers/fsdp_workers.py", line 597, in init_model
    ) = self._build_model_optimizer(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/autodl-tmp/Reasoning360/verl/workers/fsdp_workers.py", line 285, in _build_model_optimizer
    actor_module = actor_module_class.from_pretrained(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_utils.py", line 4971, in from_pretrained
    model = cls(config, *model_args, **model_kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py", line 409, in __init__
    super().__init__(config)
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_utils.py", line 2076, in __init__
    self.config._attn_implementation_internal = self._check_and_adjust_attn_implementation(
                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_utils.py", line 2691, in _check_and_adjust_attn_implementation
    lazy_import_flash_attention(applicable_attn_implementation, force_import=True)
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py", line 136, in lazy_import_flash_attention
    _flash_fn, _flash_varlen_fn, _pad_fn, _unpad_fn = _lazy_imports(implementation)
                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/lib/python3.12/site-packages/transformers/modeling_flash_attention_utils.py", line 83, in _lazy_imports
    from flash_attn import flash_attn_func, flash_attn_varlen_func
  File "/root/miniconda3/lib/python3.12/site-packages/flash_attn/__init__.py", line 3, in <module>
    from flash_attn.flash_attn_interface import (
  File "/root/miniconda3/lib/python3.12/site-packages/flash_attn/flash_attn_interface.py", line 15, in <module>
    import flash_attn_2_cuda as flash_attn_gpu
ImportError: /root/miniconda3/lib/python3.12/site-packages/flash_attn_2_cuda.cpython-312-x86_64-linux-gnu.so: undefined symbol: _ZN3c105ErrorC2ENS_14SourceLocationESs

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Processing aime: /root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet -> ./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet
Starting generation for aime at Mon Nov  3 12:53:25 CST 2025
`torch_dtype` is deprecated! Use `dtype` instead!
Processing aime: /root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet -> ./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet
Starting generation for aime at Mon Nov  3 12:55:47 CST 2025
`torch_dtype` is deprecated! Use `dtype` instead!
Processing aime: /root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet -> ./evaluation_results/test_offline_leaderboard_output//Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet
Starting generation for aime at Mon Nov  3 13:23:46 CST 2025
`torch_dtype` is deprecated! Use `dtype` instead!
DISABLE_RAY=1 detected; using local HF generation on single GPU.
{'actor': {'entropy_checkpointing': False,
           'entropy_from_logits_with_chunking': False,
           'fsdp_config': {'forward_prefetch': False, 'fsdp_size': -1},
           'strategy': 'fsdp',
           'ulysses_sequence_parallel_size': 1},
 'data': {'batch_size': 16,
          'n_samples': 4,
          'output_path': './evaluation_results/test_offline_leaderboard_output/Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet',
          'path': '/root/autodl-tmp/data/offline_eval/math__aime_repeated_8x_240.parquet',
          'prompt_key': 'prompt'},
 'model': {'attn_implementation': 'eager',
           'external_lib': None,
           'path': '/root/autodl-tmp/Qwen2.5-1.5B-Instruct',
           'trust_remote_code': True},
 'ray_init': {'num_cpus': None, 'timeline_json_file': None},
 'rollout': {'calculate_log_probs': False,
             'disable_log_stats': True,
             'do_sample': True,
             'dtype': 'bfloat16',
             'enable_chunked_prefill': True,
             'enforce_eager': True,
             'free_cache_engine': True,
             'gpu_memory_utilization': 0.5,
             'ignore_eos': False,
             'load_format': 'dummy_dtensor',
             'log_prob_micro_batch_size': None,
             'log_prob_micro_batch_size_per_gpu': 8,
             'max_model_len': None,
             'max_num_batched_tokens': 8192,
             'max_num_seqs': 1024,
             'mode': 'sync',
             'n': 1,
             'name': 'vllm',
             'prompt_length': 2048,
             'response_length': 4096,
             'temperature': 1.0,
             'tensor_model_parallel_size': 1,
             'top_k': 0,
             'top_p': 0.7},
 'trainer': {'device': 'cuda', 'n_gpus_per_node': 1, 'nnodes': 1}}
[1/60] Start to process.
[1/60] Start to generate.
[2/60] Start to process.
[2/60] Start to generate.
[3/60] Start to process.
[3/60] Start to generate.
[4/60] Start to process.
[4/60] Start to generate.
[5/60] Start to process.
[5/60] Start to generate.
[6/60] Start to process.
[6/60] Start to generate.
[7/60] Start to process.
[7/60] Start to generate.
[8/60] Start to process.
[8/60] Start to generate.
[9/60] Start to process.
[9/60] Start to generate.
[10/60] Start to process.
[10/60] Start to generate.
[11/60] Start to process.
[11/60] Start to generate.
[12/60] Start to process.
[12/60] Start to generate.
[13/60] Start to process.
[13/60] Start to generate.
[14/60] Start to process.
[14/60] Start to generate.
[15/60] Start to process.
[15/60] Start to generate.
[16/60] Start to process.
[16/60] Start to generate.
[17/60] Start to process.
[17/60] Start to generate.
[18/60] Start to process.
[18/60] Start to generate.
[19/60] Start to process.
[19/60] Start to generate.
[20/60] Start to process.
[20/60] Start to generate.
[21/60] Start to process.
[21/60] Start to generate.
[22/60] Start to process.
[22/60] Start to generate.
[23/60] Start to process.
[23/60] Start to generate.
[24/60] Start to process.
[24/60] Start to generate.
[25/60] Start to process.
[25/60] Start to generate.
[26/60] Start to process.
[26/60] Start to generate.
[27/60] Start to process.
[27/60] Start to generate.
[28/60] Start to process.
[28/60] Start to generate.
[29/60] Start to process.
[29/60] Start to generate.
[30/60] Start to process.
[30/60] Start to generate.
[31/60] Start to process.
[31/60] Start to generate.
[32/60] Start to process.
[32/60] Start to generate.
[33/60] Start to process.
[33/60] Start to generate.
[34/60] Start to process.
[34/60] Start to generate.
[35/60] Start to process.
[35/60] Start to generate.
[36/60] Start to process.
[36/60] Start to generate.
[37/60] Start to process.
[37/60] Start to generate.
[38/60] Start to process.
[38/60] Start to generate.
[39/60] Start to process.
[39/60] Start to generate.
[40/60] Start to process.
[40/60] Start to generate.
[41/60] Start to process.
[41/60] Start to generate.
[42/60] Start to process.
[42/60] Start to generate.
[43/60] Start to process.
[43/60] Start to generate.
[44/60] Start to process.
[44/60] Start to generate.
[45/60] Start to process.
[45/60] Start to generate.
[46/60] Start to process.
[46/60] Start to generate.
[47/60] Start to process.
[47/60] Start to generate.
[48/60] Start to process.
[48/60] Start to generate.
[49/60] Start to process.
[49/60] Start to generate.
[50/60] Start to process.
[50/60] Start to generate.
[51/60] Start to process.
[51/60] Start to generate.
[52/60] Start to process.
[52/60] Start to generate.
[53/60] Start to process.
[53/60] Start to generate.
[54/60] Start to process.
[54/60] Start to generate.
[55/60] Start to process.
[55/60] Start to generate.
[56/60] Start to process.
[56/60] Start to generate.
[57/60] Start to process.
[57/60] Start to generate.
[58/60] Start to process.
[58/60] Start to generate.
[59/60] Start to process.
[59/60] Start to generate.
[60/60] Start to process.
[60/60] Start to generate.
Detected 'aime' in output path, merging responses by prompt content...
Saved merged AIME responses to ./evaluation_results/test_offline_leaderboard_output/Qwen2.5-1.5B-Instruct/math__aime_repeated_8x_240.parquet
Completed generation for aime at Mon Nov  3 14:07:26 CST 2025
